{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project we decided to build a classifier to tell whenever a song (based on its audio features) is gonna be popular or not. For that purpose, have a main dataset of Spotify tracks from 1921 to 2020 from which we will use a subset of the last 10 years for this project; additionally, we have datasets for top tracks of the last 10 years, which we can use for aiding in the training and prediction of our model. The datasets we are gonna be using are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tracks - https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks\n",
    "- Top 2010 to 2019 - https://www.kaggle.com/leonardopena/top-spotify-songs-from-20102019-by-year\n",
    "- Top 2017 - https://www.kaggle.com/nadintamer/top-tracks-of-2017\n",
    "- Top 2018 - https://www.kaggle.com/nadintamer/top-spotify-tracks-of-2018\n",
    "- Top 2019 - https://www.kaggle.com/leonardopena/top50spotify2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the datases, while being from Spotify, is bit different from one another (column names, scale, etc). Therefore, the preprocessing phase of our project focuses on making these datasets compatible with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The general process we will follow for our **secondary** dataframes (top charts) is:\n",
    "\n",
    "1. Normalize the column names of each dataset so they have the same columns.\n",
    "\n",
    "2. Keep only common columns.\n",
    "\n",
    "3. Mark each dataset by year.\n",
    "\n",
    "4. Merge them into a single dataframe.\n",
    "\n",
    "We can then use our \"top charts\" dataframe for creating new features in our main dataset,\n",
    "indicating if a given track ever made it to the top charts for a given year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "\n",
    "Start by exploring our **main** dataset and our **top charts** dataset (result from preprocessing step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(name):\n",
    "    url = os.path.join(os.getcwd(), '..', 'resources', name)\n",
    "    return pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    read_dataset('tracks-1921-2020.csv'),\n",
    "    read_dataset('top-tracks-2010-to-2019.csv'),\n",
    "    read_dataset('top-tracks-2017.csv'),\n",
    "    read_dataset('top-tracks-2018.csv'),\n",
    "    read_dataset('top-tracks-2019.csv'),\n",
    "]\n",
    "\n",
    "# indices constants for easier access later one\n",
    "TRACKS_1921_2020 = 0\n",
    "TOP_2010_2019_IDX = 1\n",
    "TOP_2017_IDX = 2\n",
    "TOP_2018_IDX = 3\n",
    "TOP_2019_IDX = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the datasets have different column names to represent the same kind of metadata (name vs. title) or audio features (loudness vs. decibels). To address that, we are gonna normalize the columns so all the datasets have the same column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column normalizer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by writing a column normalizer class that we can use later. The class focuses on mapping column names to a \"desired\" column set given as parameter, the class decides what column name corresponds to what input based on similarity tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "Change = namedtuple('Change', ['before', 'after'])\n",
    "\n",
    "\n",
    "class ColumnNormalizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def _compute_best_match(self, columns, oldname):\n",
    "    \n",
    "        best_match = None\n",
    "        best_match_ratio = 0\n",
    "        \n",
    "        for colname in columns:\n",
    "            ratio = SequenceMatcher(None, colname.lower(), oldname.lower()).ratio()\n",
    "            if ratio >= 0.6 and ratio > best_match_ratio:\n",
    "                best_match = colname\n",
    "                best_match_ratio = ratio\n",
    "                \n",
    "        return best_match\n",
    "    \n",
    "    def normalize(self, desired, desired_map, df):\n",
    "        \"\"\"\n",
    "        Normalizes the column names of the given dataframe by looking at the `desired`\n",
    "        set and the `desired_map` for supervised normalization. The `desired_map` \n",
    "        should contain a mapping from old names to desired names.\n",
    "        \"\"\"\n",
    "        \n",
    "        desired = desired or set()\n",
    "        desired_map = desired_map or dict()\n",
    "        \n",
    "        guide = {name: name for name in desired}\n",
    "        guide.update(desired_map)\n",
    "        guide_keys = guide.keys()\n",
    "        \n",
    "        column_names = list(df.columns)\n",
    "        changed = list()\n",
    "        not_changed = list()\n",
    "        \n",
    "        for idx, colname in enumerate(column_names):\n",
    "            \n",
    "            best_key = self._compute_best_match(guide_keys, colname)\n",
    "\n",
    "            if best_key is not None:\n",
    "                column_names[idx] = guide[best_key]\n",
    "                changed.append(Change(colname, guide[best_key]))\n",
    "                \n",
    "            else:\n",
    "                not_changed.append(Change(colname, None))\n",
    "                \n",
    "        df.columns = column_names\n",
    "        return df, changed, not_changed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding desired columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most if not all of the datasets come from Spotify, we can look at their [API reference](https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/) to figure out which columns to expect. Easily enough, these are the most important columns we should try to get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns = [\n",
    "    \n",
    "    # metadata\n",
    "    'id',\n",
    "    'artist',\n",
    "    'title',\n",
    "    'duration_ms',\n",
    "    'genre',\n",
    "    'popularity',\n",
    "    'year',\n",
    "\n",
    "    # audio features\n",
    "    'acousticness',\n",
    "    'danceability',\n",
    "    'energy',\n",
    "    'explicit',\n",
    "    'instrumentalness',\n",
    "    'key',\n",
    "    'liveness',\n",
    "    'loudness',\n",
    "    'mode',\n",
    "    'speechiness',\n",
    "    'tempo',\n",
    "    'time_signature',\n",
    "    'valence',\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of the datasets have badly naming columns, we have to provide a a desired map to the `ColumnNormalizer` for supervised column renaming. Said map is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns_map = {\n",
    "    \n",
    "    'unamed': 'id',\n",
    "    'bpm': 'tempo',\n",
    "    'dnce': 'danceability',\n",
    "    'db': 'loudness',\n",
    "    'acous': 'acousticness',\n",
    "    'spch': 'speechness',\n",
    "    'pop': 'popularity',\n",
    "    'Track.name': 'title',\n",
    "    'beats.per.minute': 'tempo',\n",
    "    'length': 'duration_ms',\n",
    "    'dur': 'duration_ms',\n",
    "    'name': 'title',\n",
    "    'release_date': 'release_date',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying column normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the `ColumnNormalizer` on each dataset to normalize the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnorm =  ColumnNormalizer()\n",
    "\n",
    "changeset = set()\n",
    "unchangeset = set()\n",
    "\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    normalized, changed, not_changed = cnorm.normalize(desired_columns, desired_columns_map, dataset)\n",
    "    changeset.update(changed)\n",
    "    unchangeset.update(not_changed)\n",
    "    datasets[idx] = normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure no columns where left unchanged, we can simply check the `unchangeset` and make sure is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(unchangeset) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking by year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our `TOP_2010_2019_IDX` dataset is already marked by year, we only have to mark the remaining top charts datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[TOP_2017_IDX] = datasets[TOP_2017_IDX].assign(year=2017)\n",
    "datasets[TOP_2018_IDX] = datasets[TOP_2018_IDX].assign(year=2018)\n",
    "datasets[TOP_2019_IDX] = datasets[TOP_2019_IDX].assign(year=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping common columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the column names are normalized we can simply drop the columns that are not common in all our **secondary** datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab only the secondary datasets with their index\n",
    "secondary = list(enumerate(datasets))[1:]\n",
    "\n",
    "all_columns = set()\n",
    "for _, dataset in secondary:\n",
    "    all_columns.update(dataset.columns)\n",
    "\n",
    "common = set(all_columns)\n",
    "for _, dataset in secondary:\n",
    "    common.intersection_update(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we just have to update each **secondary** dataset and keep only the common column between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = sorted(list(common))\n",
    "\n",
    "for idx, dataset in secondary:\n",
    "    datasets[idx] = dataset[common_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging top charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our top charts columns are normalized, they can be merged together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artist</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>id</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>title</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Train</td>\n",
       "      <td>67.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Hey, Soul Sister</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>75.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Love The Way You Lie</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Kesha</td>\n",
       "      <td>76.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>TiK ToK</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>70.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Bad Romance</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>64.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Just the Way You Are</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Marshmello</td>\n",
       "      <td>66.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>46</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>One Thing Right</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Nicky Jam</td>\n",
       "      <td>67.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>47</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>Te Robaré</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Marshmello</td>\n",
       "      <td>69.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>48</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Happier</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>23.0</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>59.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Call You Mine</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>75.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Cross Me (feat. Chance the Rapper &amp; PnB Rock)</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acousticness            artist  danceability  duration_ms  energy  id  \\\n",
       "0           19.0             Train          67.0        217.0    89.0   1   \n",
       "1           24.0            Eminem          75.0        263.0    93.0   2   \n",
       "2           10.0             Kesha          76.0        200.0    84.0   3   \n",
       "3            0.0         Lady Gaga          70.0        295.0    92.0   4   \n",
       "4            2.0        Bruno Mars          64.0        221.0    84.0   5   \n",
       "..           ...               ...           ...          ...     ...  ..   \n",
       "45           7.0        Marshmello          66.0        182.0    62.0  46   \n",
       "46          24.0         Nicky Jam          67.0        202.0    75.0  47   \n",
       "47          19.0        Marshmello          69.0        214.0    79.0  48   \n",
       "48          23.0  The Chainsmokers          59.0        218.0    70.0  49   \n",
       "49          21.0        Ed Sheeran          75.0        206.0    79.0  50   \n",
       "\n",
       "    liveness  loudness  tempo                                          title  \\\n",
       "0        8.0      -4.0   97.0                               Hey, Soul Sister   \n",
       "1       52.0      -5.0   87.0                           Love The Way You Lie   \n",
       "2       29.0      -3.0  120.0                                        TiK ToK   \n",
       "3        8.0      -4.0  119.0                                    Bad Romance   \n",
       "4        9.0      -5.0  109.0                           Just the Way You Are   \n",
       "..       ...       ...    ...                                            ...   \n",
       "45      58.0      -2.0   88.0                                One Thing Right   \n",
       "46       8.0      -4.0  176.0                                      Te Robaré   \n",
       "47      17.0      -3.0  100.0                                        Happier   \n",
       "48      41.0      -6.0  104.0                                  Call You Mine   \n",
       "49       7.0      -6.0   95.0  Cross Me (feat. Chance the Rapper & PnB Rock)   \n",
       "\n",
       "    valence  year  \n",
       "0      80.0  2010  \n",
       "1      64.0  2010  \n",
       "2      71.0  2010  \n",
       "3      71.0  2010  \n",
       "4      43.0  2010  \n",
       "..      ...   ...  \n",
       "45     44.0  2019  \n",
       "46     80.0  2019  \n",
       "47     67.0  2019  \n",
       "48     50.0  2019  \n",
       "49     61.0  2019  \n",
       "\n",
       "[853 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_charts = pd.concat(datasets[1:])\n",
    "top_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
